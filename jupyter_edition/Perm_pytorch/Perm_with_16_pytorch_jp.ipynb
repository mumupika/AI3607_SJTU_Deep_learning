{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import torch.utils.data as Data  # to make Loader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import numpy as np \n",
    "import time\n",
    "import csv\n",
    "import pygmtools as pygm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,8,3,1,1)\n",
    "        self.bn1=nn.BatchNorm2d(8)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.maxpool=nn.MaxPool2d(2)\n",
    "        self.conv2=nn.Conv2d(8,16,3,1,1)\n",
    "        self.bn2=nn.BatchNorm2d(16)\n",
    "        #relu\n",
    "        #maxpool\n",
    "        self.conv3=nn.Conv2d(16,32,3,1,1)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "        #relu\n",
    "        #maxpool\n",
    "        self.conv4=nn.Conv2d(32,64,3,1,1)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "        #relu\n",
    "        #maxpool\n",
    "        self.conv5=nn.Conv2d(64,128,3,1,1)\n",
    "        self.bn5=nn.BatchNorm2d(128)\n",
    "        #relu\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.l1=nn.Linear(128*4*4,512)\n",
    "        self.bn6=nn.BatchNorm1d(512)\n",
    "        #relu\n",
    "        self.fc=nn.Linear(512,16)\n",
    "        #softmax\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.bn2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.bn3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.bn4(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv5(x)\n",
    "        x=self.bn5(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.flatten(x)\n",
    "        x=self.l1(x)\n",
    "        x=self.bn6(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc(x)\n",
    "        x=torch.reshape(x,(-1,4,4))\n",
    "        x=pygm.linear_solvers.sinkhorn(x)\n",
    "        #x=nn.softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_image_load(train_data):\n",
    "    batch_size=0\n",
    "    imgs=[]# for image to all images set\n",
    "    for data in train_data:\n",
    "        img,target=data\n",
    "        img=img.numpy()\n",
    "        batch_size+=1\n",
    "        for i in range(len(img)):\n",
    "            image=[]\n",
    "            '''Containing all 4 parts.'''\n",
    "            image.append(img[i][:,0:32,0:32])\n",
    "            image.append(img[i][:,32:32*2,0:32])\n",
    "            image.append(img[i][:,0:32,32:32*2])\n",
    "            image.append(img[i][:,32:32*2,32:32*2])\n",
    "            imgs.append(image)\n",
    "        if batch_size%4==0: #here change batch_size\n",
    "            imgs=np.array(imgs)\n",
    "            imgs= torch.tensor(imgs)\n",
    "            yield imgs\n",
    "            imgs=[]\n",
    "    #imgs=jt.Var(imgs).float32()\n",
    "    #return imgs\n",
    "    \n",
    "\n",
    "\n",
    "def target_generation(images):\n",
    "    '''Randomly shuffle permutation of image,Generate target'''\n",
    "    images=images.numpy()\n",
    "    rearranged_images=[]\n",
    "    targets=[]\n",
    "    for i in range(len(images)):\n",
    "        permute=np.random.permutation(4)[:4]\n",
    "        rearranged_img=[]\n",
    "        target=np.zeros((4,4))\n",
    "        for j in range(len(images[i])):\n",
    "            rearranged_img.append(images[i][permute[j]])\n",
    "            target[j][permute[j]]=1\n",
    "        #rearranged_img=torch.tensor(rearranged_img)\n",
    "        rearranged_img=np.reshape(rearranged_img,(3,64,64))\n",
    "        rearranged_images.append(rearranged_img)\n",
    "        targets.append(target)\n",
    "    rearranged_images,targets=np.array(rearranged_images),np.array(targets)\n",
    "    rearranged_images,targets=torch.tensor(rearranged_images),torch.tensor(targets)\n",
    "    return rearranged_images,targets\n",
    "\n",
    "        \n",
    "        \n",
    "def train(net,optimizer,train_data_loader,epoch,device):\n",
    "    net.train()\n",
    "    train_step=0\n",
    "    total_loss=0\n",
    "    for image in train_image_load(train_data_loader):\n",
    "        inputs,targets=target_generation(image)     #(64,3,64,64) vs (64,4,4)\n",
    "        for i in range(4):\n",
    "            inputs,targets=inputs.float().to(device),targets.float().to(device)\n",
    "            outputs=net(inputs)\n",
    "            optimizer.zero_grad()\n",
    "            outputs,targets=outputs.float(),targets.float()\n",
    "            loss=pygm.utils.permutation_loss(outputs,targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_step+=1\n",
    "            total_loss+=loss\n",
    "            if train_step%500==0:\n",
    "                print(f'epoch:{epoch},Step:{train_step},Loss:{loss}')\n",
    "                #format_text=f\"epoch:{epoch},Step:{train_step},Loss:{loss}\\n\"\n",
    "                #file.write(format_text)\n",
    "    return total_loss/train_step\n",
    "\n",
    "\n",
    "def test_image_load(test_data):\n",
    "    batch_size=0\n",
    "    imgs=[]\n",
    "    for data in test_data:\n",
    "        img,target=data\n",
    "        img=img.numpy()\n",
    "        batch_size+=1\n",
    "        for i in range(len(img)):\n",
    "            image=[]\n",
    "            '''Containing all 4 parts.'''\n",
    "            image.append(img[i][:,0:32,0:32])\n",
    "            image.append(img[i][:,32:32*2,0:32])\n",
    "            image.append(img[i][:,0:32,32:32*2])\n",
    "            image.append(img[i][:,32:32*2,32:32*2])\n",
    "            imgs.append(image)\n",
    "        imgs=np.array(imgs)\n",
    "        imgs=torch.tensor(imgs)\n",
    "        yield imgs\n",
    "        imgs=[]\n",
    "\n",
    "\n",
    "def test_target_generation(images):\n",
    "    '''Randomly shuffle permutation of image,Generate target'''\n",
    "    images=images.numpy()\n",
    "    rearranged_images=[]\n",
    "    targets=[]\n",
    "    for i in range(len(images)):\n",
    "        permute=np.random.permutation(4)[:4]\n",
    "        rearranged_img=[]\n",
    "        target=np.zeros((4,4))\n",
    "        for j in range(len(images[i])):\n",
    "            rearranged_img.append(images[i][permute[j]])\n",
    "            target[j][permute[j]]=1\n",
    "        #rearranged_img=torch.tensor(rearranged_img)\n",
    "        rearranged_img=np.reshape(rearranged_img,(3,64,64))\n",
    "        rearranged_images.append(rearranged_img)\n",
    "        targets.append(target)\n",
    "    rearranged_images,targets=np.array(rearranged_images),np.array(targets)\n",
    "    rearranged_images,targets=torch.tensor(rearranged_images),torch.tensor(targets)\n",
    "    return rearranged_images,targets\n",
    "\n",
    "def eval(outputs,target_i):\n",
    "    acc=0\n",
    "    for i in range(len(outputs)):\n",
    "        pred=torch.argmax(outputs[i],1)\n",
    "        real=torch.argmax(target_i[i],1)\n",
    "        for j in range(len(pred)):\n",
    "            if pred[j]==real[j]:\n",
    "                acc+=1\n",
    "    return acc\n",
    "\n",
    "def test(net,optimizer,test_data_loader,epoch,device):\n",
    "    test_step=0\n",
    "    total_acc=0\n",
    "    net.eval()\n",
    "    for image in test_image_load(test_data_loader):\n",
    "        inputs,targets=test_target_generation(image)\n",
    "        inputs,targets=inputs.float().to(device),targets.float().to(device)\n",
    "        outputs=net(inputs) # output(64,4),target(64,4,4)\n",
    "        acc=eval(outputs,targets)\n",
    "        total_acc+=acc/64.0\n",
    "        test_step+=1\n",
    "        if test_step%100==0:\n",
    "            print(f'epoch:{epoch},Step:{test_step},Accuracy:{acc/64.0*100}%')\n",
    "            #format_text=f'epoch:{epoch},Step:{test_step},Accuracy:{total_acc/(len(outputs)*4)*100}%\\n'\n",
    "            #file.write(format_text)\n",
    "    \n",
    "    print(f'\\n epoch:{epoch},Accuracy:{total_acc/test_step*100}%\\n')\n",
    "    #format_text=f'\\n epoch:{epoch},Accuracy:{overall_acc/test_step*100}%\\n'\n",
    "    #file.write(format_text)\n",
    "    return total_acc/test_step*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "'''The target and the full set of images have completed'''\n",
    "device = torch.device(\"cuda\")\n",
    "pygm.set_backend('pytorch')\n",
    "net=Resnet().to(device)\n",
    "learning_rate=1e-5\n",
    "optimizer=optim.SGD(net.parameters(),lr=learning_rate,momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "# 1. Get the train data\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),transforms.RandomResizedCrop((32*2,32*2),antialias=True)])\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "train_data_loader = Data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    # num_workers=2 # ready to be commented(windows)\n",
    ")\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "test_data_loader = Data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    # num_workers=2\n",
    ")\n",
    "epochs=int(1e5)\n",
    "epoch=0\n",
    "train_epoch_loss=0.0\n",
    "path=\"/root/pytorch_model.pt\"\n",
    "train_loss=[]\n",
    "test_acc=[]\n",
    "#torch.save({'epoch': 0,'model_state_dict': net.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss':0.0},path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  38\n",
      "epoch:38,Step:500,Loss:1.8922981023788452\n",
      "epoch:38,Step:1000,Loss:1.7212601900100708\n",
      "epoch:38,Step:1500,Loss:1.9927786588668823\n",
      "epoch:38,Step:2000,Loss:1.8845889568328857\n",
      "epoch:38,Step:2500,Loss:1.898523211479187\n",
      "epoch:38,Step:3000,Loss:1.8854297399520874\n",
      "epoch:38,Step:100,Accuracy:40.625%\n",
      "epoch:38,Step:200,Accuracy:60.9375%\n",
      "epoch:38,Step:300,Accuracy:35.9375%\n",
      "epoch:38,Step:400,Accuracy:51.5625%\n",
      "epoch:38,Step:500,Accuracy:32.8125%\n",
      "epoch:38,Step:600,Accuracy:48.4375%\n",
      "\n",
      " epoch:38,Accuracy:50.2675%\n",
      "\n",
      "epoch:  39\n",
      "epoch:39,Step:500,Loss:1.8303301334381104\n",
      "epoch:39,Step:1000,Loss:1.8696353435516357\n",
      "epoch:39,Step:1500,Loss:1.8749390840530396\n",
      "epoch:39,Step:2000,Loss:1.8595794439315796\n",
      "epoch:39,Step:2500,Loss:1.7932077646255493\n",
      "epoch:39,Step:3000,Loss:1.8682003021240234\n",
      "epoch:39,Step:100,Accuracy:56.25%\n",
      "epoch:39,Step:200,Accuracy:62.5%\n",
      "epoch:39,Step:300,Accuracy:56.25%\n",
      "epoch:39,Step:400,Accuracy:59.375%\n",
      "epoch:39,Step:500,Accuracy:53.125%\n",
      "epoch:39,Step:600,Accuracy:50.0%\n",
      "\n",
      " epoch:39,Accuracy:51.18000000000001%\n",
      "\n",
      "epoch:  40\n",
      "epoch:40,Step:500,Loss:1.9175302982330322\n",
      "epoch:40,Step:1000,Loss:1.8687734603881836\n",
      "epoch:40,Step:1500,Loss:1.8840103149414062\n",
      "epoch:40,Step:2000,Loss:1.8756120204925537\n",
      "epoch:40,Step:2500,Loss:1.8276138305664062\n",
      "epoch:40,Step:3000,Loss:1.8899394273757935\n",
      "epoch:40,Step:100,Accuracy:60.9375%\n",
      "epoch:40,Step:200,Accuracy:62.5%\n",
      "epoch:40,Step:300,Accuracy:54.6875%\n",
      "epoch:40,Step:400,Accuracy:50.0%\n",
      "epoch:40,Step:500,Accuracy:56.25%\n",
      "epoch:40,Step:600,Accuracy:43.75%\n",
      "\n",
      " epoch:40,Accuracy:51.032500000000006%\n",
      "\n",
      "epoch:  41\n",
      "epoch:41,Step:500,Loss:1.833435297012329\n",
      "epoch:41,Step:1000,Loss:1.8890553712844849\n",
      "epoch:41,Step:1500,Loss:1.9028300046920776\n",
      "epoch:41,Step:2000,Loss:1.8277227878570557\n",
      "epoch:41,Step:2500,Loss:1.8350727558135986\n",
      "epoch:41,Step:3000,Loss:1.8555737733840942\n",
      "epoch:41,Step:100,Accuracy:57.8125%\n",
      "epoch:41,Step:200,Accuracy:43.75%\n",
      "epoch:41,Step:300,Accuracy:54.6875%\n",
      "epoch:41,Step:400,Accuracy:43.75%\n",
      "epoch:41,Step:500,Accuracy:56.25%\n",
      "epoch:41,Step:600,Accuracy:43.75%\n",
      "\n",
      " epoch:41,Accuracy:51.55%\n",
      "\n",
      "epoch:  42\n",
      "epoch:42,Step:500,Loss:1.7809691429138184\n",
      "epoch:42,Step:1000,Loss:1.747654676437378\n",
      "epoch:42,Step:1500,Loss:1.8107562065124512\n",
      "epoch:42,Step:2000,Loss:1.9414719343185425\n",
      "epoch:42,Step:2500,Loss:1.7777540683746338\n",
      "epoch:42,Step:3000,Loss:1.8140746355056763\n",
      "epoch:42,Step:100,Accuracy:48.4375%\n",
      "epoch:42,Step:200,Accuracy:37.5%\n",
      "epoch:42,Step:300,Accuracy:59.375%\n",
      "epoch:42,Step:400,Accuracy:57.8125%\n",
      "epoch:42,Step:500,Accuracy:53.125%\n",
      "epoch:42,Step:600,Accuracy:46.875%\n",
      "\n",
      " epoch:42,Accuracy:51.542500000000004%\n",
      "\n",
      "epoch:  43\n",
      "epoch:43,Step:500,Loss:1.7893561124801636\n",
      "epoch:43,Step:1000,Loss:1.7566453218460083\n",
      "epoch:43,Step:1500,Loss:1.8694995641708374\n",
      "epoch:43,Step:2000,Loss:1.8589565753936768\n",
      "epoch:43,Step:2500,Loss:1.7853323221206665\n",
      "epoch:43,Step:3000,Loss:1.8395073413848877\n",
      "epoch:43,Step:100,Accuracy:51.5625%\n",
      "epoch:43,Step:200,Accuracy:60.9375%\n",
      "epoch:43,Step:300,Accuracy:68.75%\n",
      "epoch:43,Step:400,Accuracy:45.3125%\n",
      "epoch:43,Step:500,Accuracy:54.6875%\n",
      "epoch:43,Step:600,Accuracy:67.1875%\n",
      "\n",
      " epoch:43,Accuracy:51.790000000000006%\n",
      "\n",
      "epoch:  44\n",
      "epoch:44,Step:500,Loss:1.794149398803711\n",
      "epoch:44,Step:1000,Loss:1.8483537435531616\n",
      "epoch:44,Step:1500,Loss:1.8990644216537476\n",
      "epoch:44,Step:2000,Loss:1.7713968753814697\n",
      "epoch:44,Step:2500,Loss:1.7222310304641724\n",
      "epoch:44,Step:3000,Loss:1.8748570680618286\n",
      "epoch:44,Step:100,Accuracy:32.8125%\n",
      "epoch:44,Step:200,Accuracy:46.875%\n",
      "epoch:44,Step:300,Accuracy:46.875%\n",
      "epoch:44,Step:400,Accuracy:68.75%\n",
      "epoch:44,Step:500,Accuracy:50.0%\n",
      "epoch:44,Step:600,Accuracy:56.25%\n",
      "\n",
      " epoch:44,Accuracy:52.349999999999994%\n",
      "\n",
      "epoch:  45\n",
      "epoch:45,Step:500,Loss:1.7896775007247925\n",
      "epoch:45,Step:1000,Loss:1.819908857345581\n",
      "epoch:45,Step:1500,Loss:1.8336272239685059\n",
      "epoch:45,Step:2000,Loss:1.753392219543457\n",
      "epoch:45,Step:2500,Loss:1.8334803581237793\n",
      "epoch:45,Step:3000,Loss:1.81885826587677\n",
      "epoch:45,Step:100,Accuracy:50.0%\n",
      "epoch:45,Step:200,Accuracy:68.75%\n",
      "epoch:45,Step:300,Accuracy:51.5625%\n",
      "epoch:45,Step:400,Accuracy:26.5625%\n",
      "epoch:45,Step:500,Accuracy:39.0625%\n",
      "epoch:45,Step:600,Accuracy:53.125%\n",
      "\n",
      " epoch:45,Accuracy:52.402499999999996%\n",
      "\n",
      "epoch:  46\n",
      "epoch:46,Step:500,Loss:1.7993577718734741\n",
      "epoch:46,Step:1000,Loss:1.9827356338500977\n",
      "epoch:46,Step:1500,Loss:1.8127762079238892\n",
      "epoch:46,Step:2000,Loss:1.8577783107757568\n",
      "epoch:46,Step:2500,Loss:1.7794654369354248\n",
      "epoch:46,Step:3000,Loss:1.6992396116256714\n",
      "epoch:46,Step:100,Accuracy:53.125%\n",
      "epoch:46,Step:200,Accuracy:46.875%\n",
      "epoch:46,Step:300,Accuracy:67.1875%\n",
      "epoch:46,Step:400,Accuracy:50.0%\n",
      "epoch:46,Step:500,Accuracy:56.25%\n",
      "epoch:46,Step:600,Accuracy:51.5625%\n",
      "\n",
      " epoch:46,Accuracy:53.302499999999995%\n",
      "\n",
      "epoch:  47\n",
      "epoch:47,Step:500,Loss:1.7001553773880005\n",
      "epoch:47,Step:1000,Loss:1.7862098217010498\n",
      "epoch:47,Step:1500,Loss:1.7418723106384277\n",
      "epoch:47,Step:2000,Loss:1.8365191221237183\n",
      "epoch:47,Step:2500,Loss:1.9142788648605347\n",
      "epoch:47,Step:3000,Loss:1.713270902633667\n",
      "epoch:47,Step:100,Accuracy:53.125%\n",
      "epoch:47,Step:200,Accuracy:46.875%\n",
      "epoch:47,Step:300,Accuracy:50.0%\n",
      "epoch:47,Step:400,Accuracy:43.75%\n",
      "epoch:47,Step:500,Accuracy:57.8125%\n",
      "epoch:47,Step:600,Accuracy:53.125%\n",
      "\n",
      " epoch:47,Accuracy:53.25%\n",
      "\n",
      "epoch:  48\n",
      "epoch:48,Step:500,Loss:1.7635356187820435\n",
      "epoch:48,Step:1000,Loss:1.7762269973754883\n",
      "epoch:48,Step:1500,Loss:1.9413987398147583\n",
      "epoch:48,Step:2000,Loss:1.7286314964294434\n",
      "epoch:48,Step:2500,Loss:1.7368110418319702\n",
      "epoch:48,Step:3000,Loss:1.7263109683990479\n",
      "epoch:48,Step:100,Accuracy:56.25%\n",
      "epoch:48,Step:200,Accuracy:53.125%\n",
      "epoch:48,Step:300,Accuracy:56.25%\n",
      "epoch:48,Step:400,Accuracy:60.9375%\n",
      "epoch:48,Step:500,Accuracy:46.875%\n",
      "epoch:48,Step:600,Accuracy:59.375%\n",
      "\n",
      " epoch:48,Accuracy:53.4525%\n",
      "\n",
      "epoch:  49\n",
      "epoch:49,Step:500,Loss:1.6790176630020142\n",
      "epoch:49,Step:1000,Loss:1.874811053276062\n",
      "epoch:49,Step:1500,Loss:1.8491166830062866\n",
      "epoch:49,Step:2000,Loss:1.8258726596832275\n",
      "epoch:49,Step:2500,Loss:1.7994872331619263\n",
      "epoch:49,Step:3000,Loss:1.736851453781128\n",
      "epoch:49,Step:100,Accuracy:40.625%\n",
      "epoch:49,Step:200,Accuracy:65.625%\n",
      "epoch:49,Step:300,Accuracy:43.75%\n",
      "epoch:49,Step:400,Accuracy:56.25%\n",
      "epoch:49,Step:500,Accuracy:34.375%\n",
      "epoch:49,Step:600,Accuracy:46.875%\n",
      "\n",
      " epoch:49,Accuracy:53.5375%\n",
      "\n",
      "epoch:  50\n",
      "epoch:50,Step:500,Loss:1.727329134941101\n",
      "epoch:50,Step:1000,Loss:1.8234413862228394\n",
      "epoch:50,Step:1500,Loss:1.9650050401687622\n",
      "epoch:50,Step:2000,Loss:1.7823582887649536\n",
      "epoch:50,Step:2500,Loss:1.7469133138656616\n",
      "epoch:50,Step:3000,Loss:1.681667685508728\n",
      "epoch:50,Step:100,Accuracy:53.125%\n",
      "epoch:50,Step:200,Accuracy:45.3125%\n",
      "epoch:50,Step:300,Accuracy:54.6875%\n",
      "epoch:50,Step:400,Accuracy:51.5625%\n",
      "epoch:50,Step:500,Accuracy:50.0%\n",
      "epoch:50,Step:600,Accuracy:57.8125%\n",
      "\n",
      " epoch:50,Accuracy:54.435%\n",
      "\n",
      "epoch:  51\n",
      "epoch:51,Step:500,Loss:1.6720325946807861\n",
      "epoch:51,Step:1000,Loss:1.7843564748764038\n",
      "epoch:51,Step:1500,Loss:1.7872964143753052\n",
      "epoch:51,Step:2000,Loss:1.785309076309204\n",
      "epoch:51,Step:2500,Loss:1.8194053173065186\n",
      "epoch:51,Step:3000,Loss:1.7056708335876465\n",
      "epoch:51,Step:100,Accuracy:45.3125%\n",
      "epoch:51,Step:200,Accuracy:45.3125%\n",
      "epoch:51,Step:300,Accuracy:57.8125%\n",
      "epoch:51,Step:400,Accuracy:56.25%\n",
      "epoch:51,Step:500,Accuracy:60.9375%\n",
      "epoch:51,Step:600,Accuracy:62.5%\n",
      "\n",
      " epoch:51,Accuracy:54.362500000000004%\n",
      "\n",
      "epoch:  52\n",
      "epoch:52,Step:500,Loss:1.8092257976531982\n",
      "epoch:52,Step:1000,Loss:1.594994068145752\n",
      "epoch:52,Step:1500,Loss:1.7210056781768799\n",
      "epoch:52,Step:2000,Loss:1.7275093793869019\n",
      "epoch:52,Step:2500,Loss:1.7105433940887451\n",
      "epoch:52,Step:3000,Loss:1.7404876947402954\n",
      "epoch:52,Step:100,Accuracy:53.125%\n",
      "epoch:52,Step:200,Accuracy:56.25%\n",
      "epoch:52,Step:300,Accuracy:65.625%\n",
      "epoch:52,Step:400,Accuracy:56.25%\n",
      "epoch:52,Step:500,Accuracy:62.5%\n",
      "epoch:52,Step:600,Accuracy:50.0%\n",
      "\n",
      " epoch:52,Accuracy:55.32749999999999%\n",
      "\n",
      "epoch:  53\n",
      "epoch:53,Step:500,Loss:1.7249106168746948\n",
      "epoch:53,Step:1000,Loss:1.644628643989563\n",
      "epoch:53,Step:1500,Loss:1.7138304710388184\n",
      "epoch:53,Step:2000,Loss:1.8120417594909668\n",
      "epoch:53,Step:2500,Loss:1.7119947671890259\n",
      "epoch:53,Step:3000,Loss:1.7715691328048706\n",
      "epoch:53,Step:100,Accuracy:37.5%\n",
      "epoch:53,Step:200,Accuracy:59.375%\n",
      "epoch:53,Step:300,Accuracy:54.6875%\n",
      "epoch:53,Step:400,Accuracy:60.9375%\n",
      "epoch:53,Step:500,Accuracy:60.9375%\n",
      "epoch:53,Step:600,Accuracy:48.4375%\n",
      "\n",
      " epoch:53,Accuracy:55.34%\n",
      "\n",
      "epoch:  54\n",
      "epoch:54,Step:500,Loss:1.8023279905319214\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "while epoch < epochs:\n",
    "    checkpoint=torch.load(path)\n",
    "    epoch=checkpoint['epoch']\n",
    "    if epoch > 0:\n",
    "        #loss=checkpoint['loss']\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])   # load data from checkpoint if has trained.\n",
    "    print(\"epoch: \",epoch+1)\n",
    "    train_loss.append(train(net,optimizer,train_data_loader,epoch+1,device))\n",
    "    test_acc.append(test(net,optimizer,test_data_loader,epoch+1,device))\n",
    "    scheduler.step()\n",
    "    params=net.state_dict()\n",
    "    epoch+=1\n",
    "    torch.save({'epoch': epoch,'model_state_dict': net.state_dict(),'optimizer_state_dict': optimizer.state_dict()},path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc,'r',label=\"test_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_loss,'g',label=\"train_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jittor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
